{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层。请注意，虽然ReLU和最大汇聚层更有效，但它们在20世纪90年代还没有出现。每个卷积层5*5使用卷积核和一个sigmoid激活函数。这些层将输入映射到多个二维特征输出，通常同时增加通道的数量。第一卷积层有6个输出通道，而第二个卷积层有16个输出通道。每个2*2池操作（步骤2）通过空间下采样将维数减少4倍。卷积的输出形状由批量大小、通道数、高度、宽度决定。\n",
    "\n",
    "为了将卷积块的输出传递给稠密块，我们必须在小批量中展平每个样本。换言之，我们将这个四维输入转换成全连接层所期望的二维输入。这里的二维表示的第一个维度索引小批量中的样本，第二个维度给出每个样本的平面向量表示。LeNet的稠密块有三个全连接层，分别有120、84和10个输出。因为我们在执行分类任务，所以输出层的10维对应于最后输出结果的数量。\n",
    "\n",
    "通过下面的LeNet代码，你会相信用深度学习框架实现此类模型非常简单。我们只需要实例化一个Sequential块并将需要的层连接在一起。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net=nn.Sequential(\n",
    "    nn.Conv2d(1,6,kernel_size=5,padding=2),nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2,stride=2),\n",
    "    nn.Conv2d(6,16,kernel_size=5),nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2,stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16*5*5,120),nn.Sigmoid(),\n",
    "    nn.Linear(120,84),nn.Sigmoid(),\n",
    "    nn.Linear(84,10)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "http://zh.d2l.ai/chapter_convolutional-neural-networks/lenet.html#img-lenet-vert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape:\t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape:\t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape:\t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape:\t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape:\t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape:\t torch.Size([1, 400])\n",
      "Linear output shape:\t torch.Size([1, 120])\n",
      "Sigmoid output shape:\t torch.Size([1, 120])\n",
      "Linear output shape:\t torch.Size([1, 84])\n",
      "Sigmoid output shape:\t torch.Size([1, 84])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "#稍微测试一下\n",
    "X=torch.rand(size=(1,1,28,28),dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# 加载数据集测试\n",
    "batch_size=256\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了进行评估，我们需要对 3.6节中描述的evaluate_accuracy函数进行轻微的修改。 由于完整的数据集位于内存中，因此在模型使用GPU计算数据集之前，我们需要将其复制到显存中"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net,data_iter,device=None):\n",
    "    if isinstance(net,nn.Module):\n",
    "        net.eval()\n",
    "        if not device:\n",
    "            device=next(iter(net.parameters())).device\n",
    "        metric=d2l.Accumulator(2)   #用于对多个变量进行累加。 在上面的evaluate_accuracy函数中， 我们在Accumulator实例中创建了2个变量， 分别用于存储正确预测的数量和预测的总数量。\n",
    "        with torch.no_grad():\n",
    "            for x,y in data_iter:\n",
    "                if isinstance(x,list):\n",
    "                    x=[x.to(device) for x in x]\n",
    "                else:\n",
    "                    x=x.to(device)     #.to(device)  转到GPU上运行  ==.cuda(x)\n",
    "                y=y.to(device)\n",
    "                metric.add(d2l.accuracy(net(x),y),y.numel())  #y.numel() 返回张量的总个数\n",
    "        return metric[0]/metric[1]   #预测值/真实值"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "初始化模型参数  Xavier  http://zh.d2l.ai/chapter_multilayer-perceptrons/numerical-stability-and-init.html#subsec-xavier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "们使用交叉熵损失函数和小批量随机梯度下降"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train_ch6(net,train_iter,test_iter,num_epochs,lr,device):\n",
    "    '''\n",
    "    训练模型\n",
    "    :param net:  神经网络\n",
    "    :param train_iter:训练数据集\n",
    "    :param test_iter: 测试数据集\n",
    "    :param num_epochs: 迭代\n",
    "    :param lr:\n",
    "    :param device: GPU\n",
    "    :return:\n",
    "    '''\n",
    "    def init_weights(m):\n",
    "        if type(m)==nn.Linear or type(m)==nn.Conv2d:  #采用的网络构建模型\n",
    "            nn.init.xavier_uniform_(m.weight)#通常m这个类里包含weight bias  #均匀分布  uniform\n",
    "    net.apply(init_weights) #对模型参数进行初始化\n",
    "    print('training on:',device)\n",
    "    net.to(device)\n",
    "    optimizer=torch.optim.SGD(net.parameters(),lr=lr)  #模型每次反向传导都会给各个可学习参数p计算出一个偏导数g_{t}，用于更新对应的参数p。通常偏导数g_{t}不会直接作用到对应的可学习参数p上，而是通过优化器做一下处理，得到一个新的值\\widehat{g}_t，处理过程用函数F表示（不同的优化器对应的F的内容不同），即\\widehat{g}_t=F(g_{t})，然后和学习率lr一起用于更新可学习参数p，即p=p-\\widehat{g}_t*lr。\n",
    "    loss=nn.CrossEntropyLoss() #平方损失函数\n",
    "    animator=d2l.Animator(xlabel='epoch',xlim=[1,num_epochs],legend=['train_loss','train acc','test_acc']) #绘图已封装\n",
    "    timer,num_batches=d2l.Timer(),len(train_iter)\n",
    "    for epoch in range(num_batches):\n",
    "        metric=d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i,(X,y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l*X.shape[0],d2l.accuracy(y_hat,y),X.shape[0])\n",
    "                #为了计算精度，我们执行以下操作。 首先，如果y_hat是矩阵，那么假定第二个维度存储每个类的预测分数。 我们使用argmax获得每行中最大元素的索引来获得预测类别。 然后我们将预测类别与真实y元素进行比较。 由于等式运算符“==”对数据类型很敏感， 因此我们将y_hat的数据类型转换为与y的数据类型一致。 结果是一个包含0（错）和1（对）的张量。 最后，我们求和会得到正确预测的数量。 accuracy()\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                            (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "      f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "      f'on {str(device)}')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_28172\\2124345365.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.9\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtrain_ch6\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_iter\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtest_iter\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlr\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0md2l\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtry_gpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_28172\\3847545632.py\u001B[0m in \u001B[0;36mtrain_ch6\u001B[1;34m(net, train_iter, test_iter, num_epochs, lr, device)\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m==\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLinear\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m==\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv2d\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m#采用的网络构建模型\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m             \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxavier_uniform_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;31m#通常m这个类里包含weight bias  #均匀分布  uniform\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m     \u001B[0mnet\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minit_weights\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#对模型参数进行初始化\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'training on:'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[0mnet\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    657\u001B[0m         \"\"\"\n\u001B[0;32m    658\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 659\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m         \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    661\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    658\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    659\u001B[0m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 660\u001B[1;33m         \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    661\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    662\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_28172\\3847545632.py\u001B[0m in \u001B[0;36minit_weights\u001B[1;34m(m)\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0minit_weights\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m==\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLinear\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m==\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConv2d\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m#采用的网络构建模型\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m             \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxavier_uniform_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;31m#通常m这个类里包含weight bias  #均匀分布  uniform\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m     \u001B[0mnet\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minit_weights\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#对模型参数进行初始化\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'training on:'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\init.py\u001B[0m in \u001B[0;36mxavier_uniform_\u001B[1;34m(tensor, gain)\u001B[0m\n\u001B[0;32m    319\u001B[0m     \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3.0\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mstd\u001B[0m  \u001B[1;31m# Calculate uniform bounds from standard deviation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    320\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 321\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_no_grad_uniform_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    322\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\init.py\u001B[0m in \u001B[0;36m_no_grad_uniform_\u001B[1;34m(tensor, a, b)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_no_grad_uniform_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mtensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muniform_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "lr,num_epochs=0.9,10\n",
    "train_ch6(net,train_iter,test_iter,num_epochs,lr,d2l.try_gpu())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}